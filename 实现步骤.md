# 实现步骤

### 1、选择出前25个最相关的特征

- 注意
  - 使用Scikit-learn库的数据预处理过滤式特征选SelectKBest模型
  - SelectKBest使用方法
- [吴裕雄 python 机器学习――数据预处理过滤式特征选取SelectKBest模型](https://www.e-learn.cn/content/python/2198918)
    - [参考链接](https://blog.csdn.net/weixin_46072771/article/details/106182410?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162649066116780265459880%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162649066116780265459880&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-106182410.first_rank_v2_pc_rank_v29&utm_term=SelectKBest&spm=1018.2226.3001.4187)
    - [官方文档](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)
  - 注意到函数中的y为因变量，此处为输出标签
  - X表示的是自变量，是其他的所有变量的值

- 步骤

  - 1、首先从7个csv文件中每一个文件中抽取相等数量的攻击和良性访问的数据
    - [python——从csv文件中随机提取某几行添加到另一个csv文件中（含代码）](https://blog.csdn.net/wenqiwenqi123/article/details/105539994/?ops_request_misc=&request_id=&biz_id=102&utm_term=%E4%BB%8E%E6%AF%8F%E4%B8%AAcsv%E6%96%87%E4%BB%B6%E4%B8%AD%E9%9A%8F%E6%9C%BA%E5%8F%96%E6%8C%87%E5%AE%9A%E8%A1%8C&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-.first_rank_v2_pc_rank_v29&spm=1018.2226.3001.4187)
    - 
    
  - 2、数据预处理

    - sklearn对数据有格式要求，首先要对数据进行格式预处理。

    - 读取csv文件，并把属性放到字典列表和类标签中

      ```
      featureList = []
      labelList = []
      
      for row in reader:
          labelList.append(row[len(row)-1])
          rowDict = {}
          for i in range(1, len(row)-1):
              rowDict[headers[i]] = row[i]
          featureList.append(rowDict)
      
      print(featureList)
      
      #从表中可以看出是用字典储存，所以是无序的。
      
      # Vetorize features
      vec = DictVectorizer()
      dummyX = vec.fit_transform(featureList) .toarray()
      ```

      

- 出现问题

  - 直接导入数据后进行执行，发现出现IP地址转换为Float的问题

    ![image-20210717163840249](C:\Users\WIN10\AppData\Roaming\Typora\typora-user-images\image-20210717163840249.png)

- 长度不一致报错
  - ValueError: Found input variables with inconsistent numbers of samples: [86, 891]
  - 

- 报没有属性

  ```
  AttributeError: 'numpy.ndarray' object has no attribute 'scores_'
  ```

  - [关于“AttributeError: ‘numpy.ndarray‘ object has no attribute ‘lower‘”的解决办法](https://blog.csdn.net/weekdawn/article/details/100156218?ops_request_misc=&request_id=&biz_id=102&utm_term=AttributeError:%20%27numpy.ndarray&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-8-.first_rank_v2_pc_rank_v29&spm=1018.2226.3001.4187)

### 2、ML机器学习

#### 1）决策树

- [实例](https://blog.csdn.net/justin18chan/article/details/78715495?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.control)

- 出现问题

  - 读取文件时报错

    ```
    nicodeDecodeError: 'gbk' codec can't decode byte 0xb1 in position 5: illegal
    ```

    - 是由于测试数据的csv是由excel转换格式而成的，因此会出现换行
    - 解决：重新保存为csv文件

  - 出现MemoryError

    - [解决Python memory error的问题（四种解决方案）](https://blog.csdn.net/weixin_39750084/article/details/81501395)

- 使用测试数据产生的，决策树产生的中间结果

  ```
  digraph Tree {
  node [shape=box] ;
  0 [label=" min_seg_size_forward=32 <= 0.5\nentropy = 0.881\nsamples = 20\nvalue = [14, 6]"] ;
  1 [label="entropy = 0.0\nsamples = 14\nvalue = [14, 0]"] ;
  0 -> 1 [labeldistance=2.5, labelangle=45, headlabel="True"] ;
  2 [label="entropy = 0.0\nsamples = 6\nvalue = [0, 6]"] ;
  0 -> 2 [labeldistance=2.5, labelangle=-45, headlabel="False"] ;
  }
  ```


#### 2）

### 3、模型评估

- 评估的指标
  - Precision,正确率(TP/TP+FP)（注意:有些人把precision叫做准确率是不对的）
    Recall,召回率 TP/(TP+FN),其实就是对一个类别做一个准确率
    F1score,调和平均 harmonic mean，F1 = 2 * (precision * recall) / (precision + recall)
    ROC曲线 纵坐标是召回率，横坐标是假阳率=FP/(FP+TN),ROC曲线的面积AUC是当前分类器的平均性能，完美的分类器为AUC=1.0，而随机猜的为0.5
    ————————————————
    版权声明：本文为CSDN博主「姚贤贤」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
    原文链接：https://blog.csdn.net/u011311291/article/details/80530978
  
- 评估指标

  - | 缩写 | 全拼           | 含义                       |
    | ---- | -------------- | -------------------------- |
    | TP   | True Positive  | 预测对了，预测了“Positive” |
    | FN   | False Negative | 预测错了，预测了“Negetive” |
    | FP   | False Positive | 预测错了，预测了“Positive” |
    | TN   | True Negtive   | 预测对了，预测了“Negtive”  |

  - 指标定义

    | 指标                 | 定义                                                         | 备注                                                     |
    | -------------------- | ------------------------------------------------------------ | -------------------------------------------------------- |
    | Accuracy             | ![在这里插入图片描述](https://img-blog.csdnimg.cn/20191010224923614.png) |                                                          |
    | Precision            | ![TP /（TP+FP）](https://img-blog.csdnimg.cn/20191010224946553.png) | 对于模型标记为无误的样本中，它有多大比重是实际上也正确的 |
    | Recall / Sensitivity | ![= TP /（TP+FN）](https://img-blog.csdnimg.cn/20191010225034585.png) | 对于实际上是正确的样本，它有多大比重被模型无误的找出来了 |
    | F1 - Score           | ![2*Precision*Recall / （Precision + Recall)](https://img-blog.csdnimg.cn/20191010225042218.png) | 取值范围是从-到1的。1是最好，0是最差                     |

- 步骤

  - ML机器学习后，使用基于混淆矩阵的

- [混淆矩阵](https://blog.csdn.net/weixin_30675967/article/details/97809675)

  - 定义

    - 在机器学习领域，混淆矩阵（*confusion matrix\*），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的效果，通常是监督学习（非监督学习，通常用匹配矩阵：\*matching matrix\*）。
    - 就是对机器学习算法的运行结果进行评价，效果如何，精确度怎么样而已。

  - 使用场景

    - 如给了猫狗的图片进行训练后预测的结果可能如下图，表示了预测和真实的结果。

      ![img](https://img-blog.csdn.net/20150407223936418?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdmVzcGVyMzA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

  - 组成

    - 由false positives，falsenegatives，true positives和true negatives组成两行两列

    - 对于猫的类别混淆表格![img](https://img-blog.csdn.net/20150407224047442?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdmVzcGVyMzA1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

      - 总共8只猫给你预测：

        5只猫都对了（true positive）       2只狗错当成了猫

        3只猫错当成狗了（false negative）  剩下的（27-5-2-3）=17 （总共27只洞府）都对啦。

  - 使用方法

    - 直接利用Accord 提供的类进行统计。

      ```
      using Accord.Statistics.Analysis 
      
      // 机器学习的预测结构
       bool[] expected = Classes.Decide(table.GetColumn(2));
      
      // 实际结果
       bool[] output = svm.Decide(inputs);
      
       // Use confusion matrix to compute some performance metrics
      dgvPerformance.DataSource = new [] { new ConfusionMatrix(output, expected) };
      ```

### 3、备注

#### 1）Python从csv中读取数据的方法

- [链接](https://blog.csdn.net/lucky_shi/article/details/105321149?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162650775216780271599335%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=162650775216780271599335&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-3-105321149.first_rank_v2_pc_rank_v29&utm_term=python%E4%BB%8Ecsv%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE&spm=1018.2226.3001.4187)

